{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Setup",
   "id": "da1981348442a4b2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T20:41:27.669518Z",
     "start_time": "2025-05-12T20:41:24.842526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Description:\n",
    "------------\n",
    "This script initializes a full PyTorch training environment with:\n",
    "\n",
    "- Modular imports for data, logging, MLflow, ONNX, and more\n",
    "- Logger setup via Loguru with structured file logging\n",
    "- MLflow experiment initialization and run lifecycle management\n",
    "- Device detection (CUDA or CPU) and runtime settings\n",
    "- Optional support for ONNX runtime inference\n",
    "- Color-coded console output (colorama) for easier debugging\n",
    "- Preloaded `requirements.txt` for reproducibility tracking\n",
    "\n",
    "This script is intended to be imported into downstream training or inference modules.\n",
    "\"\"\"\n",
    "\n",
    "# --- Basic Utilities ---\n",
    "import datetime as dt\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "import json\n",
    "import functools\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Data Manipulation ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Validation ---\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "\n",
    "# --- Visualization ---\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Latex, Math\n",
    "\n",
    "# --- Console Formatting ---\n",
    "from colorama import Fore, Style\n",
    "\n",
    "# --- Logging Framework ---\n",
    "from loguru import logger\n",
    "import uuid\n",
    "\n",
    "# --- MLflow for Experiment Tracking ---\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import mlflow.sklearn\n",
    "from mlflow.data import from_pandas\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "# --- ONNX Runtime (Optional) ---\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "\n",
    "# Add the below onnx code to FastAPI for deployment\n",
    "# @app.on_event(\"startup\")\n",
    "# def load_model():\n",
    "#     global session\n",
    "#     session = ort.InferenceSession(\n",
    "#         \"model.onnx\",\n",
    "#         providers=[\"CUDAExecutionProvider\", \"CPUExecutionProvider\"]\n",
    "#     )\n",
    "\n",
    "\n",
    "# --- Scientific Computation ---\n",
    "import scipy as sp\n",
    "import sympy as sym\n",
    "from plotly.data import experiment\n",
    "\n",
    "# --- Scikit-Learn ---\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
    ")\n",
    "\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler, MinMaxScaler, RobustScaler,\n",
    "    OneHotEncoder, OrdinalEncoder\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import (\n",
    "    LogisticRegression, ElasticNet, Ridge, Lasso\n",
    ")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, ConfusionMatrixDisplay,\n",
    "    classification_report, accuracy_score,\n",
    "    mean_squared_error, mean_absolute_error, r2_score\n",
    ")\n",
    "\n",
    "# --- PyTorch Core ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# --- Joblib for Model Serialization ---\n",
    "import joblib\n",
    "\n",
    "# --- Optional: Config Frameworks (commented) ---\n",
    "# from omegaconf import OmegaConf\n",
    "# import hydra\n",
    "\n",
    "# --- Secrets Management ---\n",
    "sys.path.append(\"/mnt/git/github/gabemcwilliams/common-components/security\")\n",
    "from vault_mgr import *\n",
    "\n",
    "os.environ[\"MLFLOW_TRACKING_INSECURE_TLS\"] = \"false\"\n",
    "\n",
    "# --- PyTorch Runtime Setup ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"[INFO] Using device: {device}\")\n",
    "print(f\"[INFO] PyTorch version: {torch.__version__}\")\n",
    "torch.set_num_threads(32)"
   ],
   "id": "7ffd933dcbd8d08a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/mls/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: cuda\n",
      "[INFO] PyTorch version: 2.6.0+cu124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/mls/venv/lib/python3.12/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Logger",
   "id": "3a3391e2afc97e69"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T15:38:45.516570Z",
     "start_time": "2025-05-06T15:38:45.430855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- MLflow Experiment Setup ---\n",
    "experiment_name = \"torch_custom_datasets\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# --- Store requirements.txt as obj for logging ref\n",
    "with open('/mnt/git/requirements.txt') as f:\n",
    "    requirements = f.read().splitlines()\n",
    "\n",
    "# --- Init MLflow Run ---\n",
    "\n",
    "# kill unclosed run if exists\n",
    "if mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "run = mlflow.start_run()\n",
    "\n",
    "# --- Logging Initialization ---\n",
    "\n",
    "# Create log directory for the experiment\n",
    "log_dir = Path(\"/mnt/mls/logs\") / experiment_name\n",
    "log_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Define log file path\n",
    "log_file = log_dir / f\"train_{experiment_name}.log\"\n",
    "timestamp = str(dt.datetime.now(dt.timezone.utc).strftime(\"%Y_%m_%d_%H%M%S\"))\n",
    "run_id = run.info.run_id\n",
    "\n",
    "logger.remove()\n",
    "\n",
    "logger = logger.bind(run_id=run_id)\n",
    "logger = logger.bind(run_id=run_id, timestamp=timestamp)\n",
    "\n",
    "# File logging with daily rotation and compression\n",
    "logger.add(\n",
    "    str(log_file),  # Path to the log file (must be a string, not a Path object)\n",
    "\n",
    "    format=\"{extra[timestamp]} | {level} | {extra[run_id]} | {name}:{function}:{line} | {message}\",\n",
    "    # Format of each log line:\n",
    "    # {time}     - Timestamp (YYYY-MM-DD HH:MM:SS.mmm)\n",
    "    # {level}    - Log level (INFO, DEBUG, etc.)\n",
    "    # {name}     - Module name (e.g., 'helper' from 'helper.py')\n",
    "    # {function} - Name of the function that emitted the log\n",
    "    # {line}     - Line number where logger was called\n",
    "    # {message}  - The actual message logged\n",
    "\n",
    "    level=\"DEBUG\",  # Minimum log level for this handler (includes INFO, WARNING, ERROR, etc.)\n",
    "    rotation=\"00:00\",  # Automatically rotate log file when \"00:00\" for daily rotation\n",
    "    retention=\"14 days\",  # Keep rotated log files for 14 days, then delete them automatically\n",
    "    compression=\"zip\",  # Compress rotated log files using ZIP format to save space\n",
    "    enqueue=True,  # Use multiprocessing-safe queue to log from multiple threads/processes safely\n",
    "    backtrace=True,  # Show full stack trace (even outside of the except block) if an error occurs\n",
    "    diagnose=False,  # Disable automatic introspection of variables in the traceback (safer for production)\n",
    "    mode=\"a\",  # Open the log file in append mode (ensures logs arenâ€™t overwritten on script restart)\n",
    "    filter=lambda record: record[\"extra\"].get(\"run_id\") == run_id  # Optional, if multiple run_ids used\n",
    ")\n",
    "\n",
    "\n",
    "def log_time(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        logger.info(f\"{func.__name__} took {end_time - start_time:.4f} seconds\")\n",
    "        return result\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "logger.info(\"Logger initialized (mlflow.start_run()).\")"
   ],
   "id": "2ca4adacabfa85ad",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "64101779ef4803f2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
